---
layout: post
title: Nginx性能
key: 20180223
tags: Nginx
---

## Nginx性能

### tcp_nodelay,tcp_nopush和sendfile

#### tcp_nodelay

>在TCP发展早期，工程师需要面对流量冲突和堵塞的问题，其中涌现了大批的解决方案，其中之一是由John Nagle提出的算法。

>Nagle的算法旨在防止通信被大量的小包淹没，该理论不涉及全尺寸的tcp包(最大报文长度，简称MSS)的处理，只针对比MSS小的包。只有当接收方成功地将以前的包(ACK)的所有确认发回来时，这些包才会被发送。在等待期间，发送方可以缓冲更多的数据之后在发送。
<pre>
if package.size >= MSS.szie
   send(package)
elsif acks.all_received?
   send(package)
else
   # acumulate date
end
</pre>

>与此同时，诞生了另外一个理论，延时ACK

>在TCP通信中，在发送数据后，需要接受回应包(ACK)来确认数据被成功传达。

>延时ACK旨在解决线路被大量的ACK包拥堵的状况。为了减少ACK的数量，接受者等待需要回传的数据加上ACK包回传给发送方，如果没有数据需要回传，必须在至少每2个MSS，或者200至500毫秒内发送ACK(以防我们不在收到ACK包)。

<pre>
if packages.any?
  send
elsif last_ack_send_more_then_2MSS_ago? || 200_ms_500_timer.finished?
  send
else
  # wait
end
</pre>
>正如可能在一开始就注意到的那样————这可能会导致持久连接上的一些暂时的锁死。让我们重视它。

假设：

- 初始拥塞窗口等于2，拥塞窗口是另一个TCP机制的一部分，称为慢启动。细节并不重要，只要记住它限制了一次可以发送多少个包。在第一次往返中，我们可以发送2个MSS包。在第二次发送中：4个MSS包，第三次发送8个MSS包，以此类推。
- 四个已缓存的等待发送的数据包：A,B,C,D
- A,B,C是MSS包
- D是小包

场景：

- 由于是初始的拥塞窗口，发送端被允许传送两个包：A和B

- 接收端在成功获得这两个包之后，发送一个ACK

- 发送端发送C包。软后，Nagle却阻止它发送D包(包长度太小，等待C包的ACK)

- 在接收端，延时ACK使他无法发送ACK(每隔2个包或者200毫秒发送一次)

- 在200ms之后，接收端发送C包的ACK

- 发送端收到ACK并发送D包

如图所示：

![nginxtcp](https://blog.maihill.com/assets/images/pic/nginx/TCP%E5%BB%B6%E8%BF%9F%E7%AD%96%E7%95%A5.jpg "nginxtcp")

>在这个数据交换过程中，由于Nagle和延时ACK之间的死锁，引入了200毫秒的延迟

>Nagle算法是当时正真的救世主，而且目前任然具有极大的价值。但在大多数情况下，我们不会在我们的网站上使用它，因此可以通过添加TCP_NODELAY标志来安全的关闭它。来享受200毫秒的提速效果。
<pre>
tcp_nodelay on; # sets TCP_NODELAY flag, used on keep-alive connections
</pre>


#### sendfile
正常来说，党要发送一个文件时需要下面的步骤：

- malloc(3)——分配一个本地缓冲区，储存对象数据

- read(2)——检索和复制对象到本地缓冲区

- write(2)——从本地缓冲区复制对象到socket缓冲区

>这涉及到两个上下文切换(读、写)，并使相同对象的第二个副本成为不必要的。正如你所看到的，这不是最佳方式。值得庆幸的是还有另一个系统调用，提升了发送文件(的效率)，它北称为：sendfile(2).这个调用在文件cache中检索一个对象，并传递指针(不需要复制整个对象)，直接传递到socket描述符，Netflix表示，使用sendfile(2)将网络吞吐量从6Gbps提高到30Gbps。

sendfile(2)有一些注意事项：

- 不可用于UNIX socket(当通过你的上游服务器发送静态文件时)

- 能否执行不同的操作，取决于操作系统

在Nginx中打开sendfile(2)的方法：
<pre>
sendfile on;
</pre>

#### tcp_nopush

>tcp_nopush和tcp_nodelay相反。不是为了尽可能快的推送数据包，它的目标是一次性优化数据的发送量。

>在发送客户端之前，它将强制等待包达到最大长度(MSS),而且这个指令只在sendfile开启时才起作用。

设置方法如下：

<pre>
sendfile on;
tcp_nopush on;
</pre>

看起来tcp_nopush和tcp_delay是互斥的，但是，如果所有三个指令都开启，Nginx会怎样呢？

- 确保数据包在发送给客户端之前是满的

- 对于最后一个数据包，tcp_nopush将被删除，允许TCP立即发送，没有200毫秒的延迟

### 到底应该使用多少个进程呢？

#### 工作进程

>worker_process指令会指定：应该运行都少个worker。默认情况下此值为1，最安全的设置是通过传递auto选项来使用核心数。

>但由于Nginx架构，其处理请求的速度非常快，我们可能一次不会使用超过2-4个进程(除非你在托管很大的网站如百度等或者Nginx内部在执行一些CPU密集型任务)。

设置方法：

<pre>
worker_process auto;
</pre>

#### worker连接
>与worker_process直接绑定的指令时worker_connections.它指定一个工作进程可以一次打开多少个连接，这个数目包括所有连接(与代理服务器的连接)，而不仅仅是与客户端的连接，此外，值得记住的是，一个客户端可以打开多少个连接，同时获取其他资源。

设置方法：
<pre>
worker_connections 1024;
</pre>

#### 打开文件数目限制

>在基于Unix系统中的"一切都是文件"，这以为着文档，目录，管道甚至套接字都是文件。系统对一个进程可以打开多少个文件有一个限制，查看该限制：

<pre>
ulimit -Sn # soft ulimit
ulimit -Sn # hard ulimit
</pre>
>这个系统必须根据worker_connections进行调整，任何传入的连接都会打开至少一个文件(通常是两个套接字或者磁盘上的静态文件)。所以这个值等于worker_connections * 2是安全的。幸运的是，Nginx提供了一个配置选项来增加这个系统值，要使用这个配置，请添加具有适当数目的worker_rlimit_nofile指令并重新加载Nginx。

设置方法：
<pre>
worker_rlimit_nofile 2048;
</pre>

完整详细配置：
<pre>
worker_process auto;
worker_rlimit_nofile 2048; # Changes the limit on the maximun munber of open file(RLIMIT_NOFILE)for worker processes
worker_connections 1024; # Sets the maximnu mumber of simultaneous connections that can be opened by a worker processes
</pre>

#### 最大连接数

可以计算出可以处理多少给并发：
<pre>
最大连接数 =
   worker_process * worker_connections

   (keep_alive_timeout + avg_response_time) / 2
</pre>

>keep_alive_timeout + avg_response_time 单个连接持续多久，除以2，通常情况下一个客户端打开两个连接，一个Nginx和客户端之间，另一个在Nginx和上游服务器之间。

### Gzip

启用gzip可以显著降低响应的(报文)大小，因此，客户端(网页)会显得更快些

#### 压缩级别

>Gzip有不同的压缩级别，1 到 9 级。递增这个级别将会减少文件的大小，但也会增加资源消耗。作为标准将这个数字（级别）保持在 3 - 5 级，就像上面说的那样，它将会得到较小的节省，同时也会得到更大的 CPU 使用率。这有个通过 gzip 的不同的压缩级别压缩文件的例子，0 代表未压缩文件。


#### gzip\_http\_version 1.1;

>这条指令告诉nginx仅在HTTP 1.1 以上的版本才能使用 gzip,在这里不涉及 HTTP 1.0，至于 HTTP 1.0 版本，它是不可能既使用keep-alive和gzip的。因此你必须做出决定：使用 HTTP 1.0 的客户端要么错过 gzip，要么错过 keep-alive

配置：

<pre>
gzip on;        # enable gzip
gzip_http_version 1.1;   # turn on gzip for http 1.1 and above
gzip_disable "msie6";    # IE 6 hed issues with gzip
gzip_comp_level 5;       # inc compresion level,and CPU usage
gzip_min_length 100;     # minimal weight to gzip file
gzip_proxied any;        # enable gzip proxied requests (e.g. CDN)
gzip_buffers 16 8k;      # compresssion buffers(if we execed this value,sisk will be used instead of RAM)
gzip_vary on;            # add header Vary Accept-Encoding (more on that in Caching section)

# define files which should be compression
gzip_types text/plain;
gzip_types text/css;
gzip_types application/javascript;
gzip_typss application/json;
gzip_types application/vnd.ms-fontobject;
gzip_types application/x-font-ttf;
gzip_types font/opentype;
gzip_types image/svg+xml;
gzip_types image/x-icon;
</pre>

### 缓存

缓存，它能提升用户的请求速度。

管理缓存可以由2个header来控制：

- 在HTTP/1.1中用Cache-Control管理缓存

- Pragma 对于HTTP/1.0客户端的向后兼容性

缓存本身可以分成两类：公共缓存和私有缓存。公共缓存是被多个用户共同使用的。专用缓存专用于单个用户。

设置方法：
<pre>
add_header Cache-Control pulbic;
add_header Pragma public;
</pre>

对于标准资源，建议保留时间是1个月：
<pre>
location ~* \.(jpg|jpeg|png|gif|ico|css|js) {
   expires 1M;
   add_header Cache-Control public;
   add_header Pragma public;
}
</pre>

使用公共存储的主意事项：

如何将我们的资源存储在公共存储(如CDN)中，URI将是唯一的标识。在这种情况下，Nginx的gzip功能是开启的。

有2个浏览器：

- 旧的，不支持gzip

- 新的，支持gzip

旧的浏览器给CDN发送了一个maihill.com/style的请求。但是CDN也没有这个资源，它将给我们的服务器发送请求，并且放回未经压缩的响应。CDN在哈西里存储文件(以后使用)
<pre>
{
......
maihill.com/style.css     FILE("style/maihill/style.css")
......
}
</pre>
然后将其内容返回给请求客户端

现在，新的浏览器发送相同的请求到CDN，请求maihill/style.css,获取gzip打包的资源。由于CDN仅通过URI标识资源，它将为新浏览器返回一样的未压缩的资源，新的浏览器将尝试提取未打包的文件，但是将获得无用的东西。

如果我们能告诉公共缓存是怎样进行URI和编码的资源识别，就可以避免这个问题。

<pre>
{
......
(maihill.com/style.css, gzip)   FILE("style/maihill/style.css.gzip")
(maihill.com/style.css, text/css)    FILE("/sites/maihill.style.css")
......
}
</pre>

这正是Vary Accept-Encoding:完成的，它告诉公共缓存，可以通过URI和Accetp-Encoding区分资源。

配置方法：

<pre>
location ~* \.(jpg|jpeg|png|gif|ico|css|js) {
      expires 1M;
      add_header Cache-Control public;
      add_header Pragma public;
      add_header Vary Accept-Encoding; 
}
</pre>

### 超时

client\_body\_timeout和client\_header\_timeout定义了Nginx在抛出408(请求超时)请求错误之前应该等待客户端传输主体或头信息的时间。

send\_timeout 设置向客户单发送响应的超时时间。超过尽在两次连续的写入操作之间被设置，而不是用于整个响应的传输过程。如果客户端在给定的时间内没有收到任何内容，则连接将关闭。

设置这些值的时候要小心，因为等待时间长会使你容易收到攻击者的攻击，并且等待时间太短的话会切断速度较慢的客户单的连接。

设置方法：

<pre>
# Configure timeouts
client_body_timeout 12;
client_header_timeout 12;
send_timeout 10;
</pre>

### Buffers(缓冲)

client\_body\_buffer\_size

设置读取客户端请求正文的缓冲区大小。如果请求主体大于缓冲区，则整个主体或仅其部分被写入临时文件。对client\_body\_buffer\_size而言，设置16k大小在大多数情况下是足够的。

这是有一个可以产生巨大影响的设置，必须谨慎使用。太小了则Nginx会不断使用I/O把剩余的部分写进文件。太大了，则当攻击者可以打开所有连接但你无法在系统上分配足够缓冲来处理这些连接时，你可能容易受到DOS攻击。

client\_header\_buffer\_size 和 large\_client\_header\_buffer

如果header不能跟client\_haeder\_baffer\_size匹配上,就会使用large\_client\_header\_buffer.如果请求也不合适large\_client\_header\_buffer，将给客户端返回一个错误提示，对于大多数的请求来说，1kb的缓存是足够的。但是，如果一个包含大量记录的请求，1kB是不够的。

如果请求行的的长度超限，将给客户端返回一个414(请求的URI太长)错误提示。如果请求的header超限，将抛出一个400(错误请求)的错误代码。

client\_max\_body\_size

设置客户端请求主体的最大允许范围，在请求头字段中指定"内容长度"。如果你希望允许用户上传文件，调整此配置以满足你的需求。

配置如下：

<pre>
client_body_buffer_size     16k;
client_header_buffer_size      1k;
large_client_header_buffer    2 1k;
client_max_body_size         8m;
</pre>

### Keep-Alive

HTTP所依赖的TCP协议需要执行三次握手来启动连接。这意味着在服务器可发送数据之前，需要在客户机和服务器之间进行三次完整的往返。

假设你在百度请求一张图片/image.jpg,并连接到离你最近的服务器Chengdu：

<pre>
Open connection

TCT Hardshake:
Baidu ——>-------------synchronize packet (SYN) ---------------——> Chengdu
Baidu <——----synchronise-acknowledgement packet (SYN-ACK)-----<—— Chengdu
Baidu ——>----------acknowledgement (ACK)---------------------——> Chengdu

Date Transfer:
Baidu ——>---------------------/image.jpg---------------------——> Chengdu
Baidu <——-------------------(image data)---------------------<—— Chengdu

Close connection
</pre>

对于另一个请求，你将不得不再次执行整个初始化。如果你在短时间内发送多次请求，这可能会快速累积起来。这样的话keep-alive使用起来就方便多了。在成功响应它之后，它保持连接空闲给定的时间段(例如：10秒)。如果在这段时间内有另外一个请求，现有的连接将被重用，空闲时间将被刷新。

Nginx提供了几个指令来调整keep alive设置，可以分为两类：

- 在客户端和Nginx之间keey\_alive

>keepavlie\_disable  msie6;     # disable selected browsers

> \# The mumber of requests a client can make over a single keepalive connection.The default is 100,but a much higher value can be especially useful  for testing  with a load-generation tool,which generally sends a large number of requests from single client.

>keepalive_requests 100000;

> \# How long an idle keepalive connection remains open.

>keepalive\_timeout 60;

- 在Nginx和上游服务器之间keep\_alive

<pre>
upstream backend {
    # The munber of idle keepalive connection to an upstream server that remain open of each worker process
    keepalive 16;
}
server {
    location /http/ {
        proxy_pass http://http_backend;
        proxy_http_version 1.1;
        proxy_set_header Connection "";
    }
}
</pre>
